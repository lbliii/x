
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Adaptive (Asynchronous) Method &#8212; project-x 0.0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js?v=dc820ae5"></script>
    <script src="../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha';</script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
    <p class="title logo__title">project-x 0.0.1 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../index.html">
                    Welcome to project-x’s documentation!
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Model Developer Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../model-hub-library/index.html">Model Hub Library</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../model-hub-library/transformers/overview.html">Huggingface Trainsformers</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../model-hub-library/transformers/tutorial.html">Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../model-hub-library/transformers/examples.html">Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../model-hub-library/mmdetection/overview.html">MMDetection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/pytorch-mnist-local-qs.html">Run Your First Experiment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/pytorch-mnist-tutorial.html">PyTorch MNIST Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/pytorch-porting-tutorial.html">PyTorch Porting Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/tf-mnist-tutorial.html">TensorFlow Keras Fashion MNIST Tutorial</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/docs/model-dev-guide/hyperparameter/search-methods/hp-adaptive-asha.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Adaptive (Asynchronous) Method</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> {your-title} </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-start">Quick start</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#details">Details</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">ASHA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-asynchronous-halving">Why Asynchronous Halving?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-over-asha">Adaptive over ASHA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#faq">FAQ</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="adaptive-asynchronous-method">
<span id="topic-guides-hp-tuning-det-adaptive-asha"></span><h1>Adaptive (Asynchronous) Method<a class="headerlink" href="#adaptive-asynchronous-method" title="Permalink to this heading">#</a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code> search method employs an Asynchronous version of the Successive Halving
Algorithm (<a class="reference external" href="https://arxiv.org/pdf/1810.05934.pdf">ASHA</a>), which is suitable for large-scale
experiments with hundreds or thousands of trials.</p>
<section id="quick-start">
<h2>Quick start<a class="headerlink" href="#quick-start" title="Permalink to this heading">#</a></h2>
<p>Here are some suggested initial settings for <code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code> that typically work well.</p>
<p>Search mode:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code>: Set to <code class="docutils literal notranslate"><span class="pre">standard</span></code>.</p></li>
</ul>
<p>Resource budget:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_length</span></code>: The maximum training length (see <span class="xref std std-ref">Training Units</span>) of any trial that survives to the end of the
experiment. This quantity is domain-specific and should roughly reflect the number of minibatches
the model must be trained on for it to converge on the data set. For users who would like to
determine this number experimentally, train a model with reasonable hyperparameters using the
<code class="docutils literal notranslate"><span class="pre">single</span></code> search method.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_trials</span></code>: This indicates the total number of hyperparameter settings that will be evaluated
in the experiment. Set <code class="docutils literal notranslate"><span class="pre">max_trials</span></code> to at least 500 to take advantage of speedups from
early-stopping. You can also set a large <code class="docutils literal notranslate"><span class="pre">max_trials</span></code> and stop the experiment once the desired
performance is achieved.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_concurrent_trials</span></code>: This field controls the degree of parallelism of the experiment. The
experiment will have a maximum of this many trials training simultaneously at any one time. The
<code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code> searcher scales nearly perfectly with additional compute, so you should set
this field based on compute environment constraints. If this value is less than the number of
brackets produced by the adaptive algorithm, it will be rounded up.</p></li>
</ul>
</section>
<section id="details">
<h2>Details<a class="headerlink" href="#details" title="Permalink to this heading">#</a></h2>
<p>Conceptually, the <code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code> searcher is a carefully tuned strategy for spawning multiple
<em>ASHA</em> (asynchronous successive halving algorithm) searchers, themselves hyperparameter search
algorithms. ASHA can be configured to make different tradeoffs between exploration and exploitation,
i.e., how many trials are explored versus how long a single trial is trained for. Because the right
tradeoff between exploration and exploitation is hard to know in advance, the <code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code>
algorithm tries several ASHA searches with different tradeoffs.</p>
<p>The configuration settings available to Determined experiments running in <code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code> mode
mostly affect the ASHA subroutines directly. The <code class="docutils literal notranslate"><span class="pre">mode</span></code> configuration is the only one affecting
the decisions of the <code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code> searcher, by changing the number and types of ASHA
subroutines spawned.</p>
<p>The first section here gives a description of the synchronous version of ASHA called successive
halving. The second section discusses the motivation for the asynchronous promotions used by ASHA.
The third section describes why you would choose adaptive_asha over plain asynchronous_halving. The
final section and conclusion is a set of FAQs regarding <code class="docutils literal notranslate"><span class="pre">adaptive_asha</span></code>.</p>
<section id="id1">
<h3>ASHA<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>At a high level, SHA prunes (“halves”) a set of trials in successive rounds we call <em>rungs</em>. SHA
starts with an initial set of trials. (A trial means one model, with a fixed set of hyperparameter
values.) SHA trains all the trials for some length and the trials with the worst validation
performance are discarded. In the next rung, the remaining trials are trained for a longer period of
time, and then trials with the worst validation performance are pruned once again. This is repeated
until the maximum training length is reached.</p>
<p>First, an example of SHA.</p>
<ul class="simple">
<li><p>Rung 1: SHA creates N initial trials; the hyperparameter values for each trial are randomly
sampled from the hyperparameters defined in the experiment configuration file. Each trial is
trained for 1 epoch, and then validation metrics are computed.</p></li>
<li><p>Rung 2: SHA picks the N/4 top-performing trials according to validation metrics. These are
trained for 4 epochs.</p></li>
<li><p>Rung 3: SHA picks the N/16 top-performing trials according to validation metrics. These are
trained for 16 epochs.</p></li>
</ul>
<p>At the end, the trial with best performance has the hyperparameter setting the SHA searcher returns.</p>
<p>In the example above, we generalize “halving” with a field called divisor, which determines what
fraction of trials are kept in successive rungs, as well as the training length in successive rungs.
<code class="docutils literal notranslate"><span class="pre">max_length</span></code> is 16 epochs, which is the maximum length a trial is trained for.</p>
<p>In general, SHA has a fixed <code class="docutils literal notranslate"><span class="pre">divisor</span></code> d. In the first rung, it generates an initial set of
randomly chosen trials and runs until each trial has trained for the same length. In the next rung,
it keeps 1/d of those trials and closes the rest. Then it runs each remaining trial until it has
trained for d times as long as the previous rung. ASHA iterates this process until some stopping
criterion is reached, such as completing a specified number of rungs or having only one trial
remaining. The total training length, rungs, and trials within rungs are fixed within each SHA
searcher, but vary across different calls to SHA by the adaptive algorithm. Note that although the
name “SHA” includes the phrase “halving”, the fraction of trials pruned after every rung is
controlled by <code class="docutils literal notranslate"><span class="pre">divisor</span></code>.</p>
</section>
<section id="why-asynchronous-halving">
<h3>Why Asynchronous Halving?<a class="headerlink" href="#why-asynchronous-halving" title="Permalink to this heading">#</a></h3>
<p>Successive halving (SHA) promotes hyperparameter configurations synchronously, waiting for each rung
to complete before performing any promotions. This allows the algorithm to have complete information
about all trials at the time of promotion, but it results in underutilized nodes waiting on
completion of validation steps for other configurations. ASHA, asynchronous successive halving,
asynchronously promotes trials when it has the minimum information required to make a decision in
order to maximize compute efficiency of the searcher. In contrast to SHA which initializes all
trials in the bottom rung at the outset, ASHA will continuously add trials to the bottom rung until
the desired number of trials is reached.</p>
<p>See the difference in asynchronous vs. synchronous promotions in the two animated GIFs below:</p>
<img alt="Determined AI successive halving (SHA) animation showing how each rung waits to complete before performing promotions." src="assets/images/sha.gif" />
<img alt="Determined AI asynchronous successive halving (ASHA) animation showing how each trials are continuously added to the bottom rung until the desired number is reached." src="assets/images/asha.gif" />
</section>
<section id="adaptive-over-asha">
<h3>Adaptive over ASHA<a class="headerlink" href="#adaptive-over-asha" title="Permalink to this heading">#</a></h3>
<p>The adaptive algorithm calls ASHA subroutines with varying parameters. The exact calls are
configured through the choice of <code class="docutils literal notranslate"><span class="pre">mode</span></code>, which specifies how aggressively to perform early
stopping. One way to think about this behavior is as a spectrum that ranges from “one ASHA run”
(aggressive early stopping; eliminate most trials every rung) to “<code class="docutils literal notranslate"><span class="pre">searcher:</span> <span class="pre">random</span></code>” “multiple
ASHA runs, some of which will not early stop and others will early stop later” (try some without
early stopping; initialized trials may be allowed to run to completion).</p>
<p>On one end, <code class="docutils literal notranslate"><span class="pre">aggressive</span></code> applies early stopping in a very eager manner; this mode essentially
corresponds to only making a single call to ASHA. With the default <code class="docutils literal notranslate"><span class="pre">divisor</span></code> of 4, 75% of the
remaining trials will be eliminated in each rung after only being trained for 25% the length of the
next rung. This implies that relatively few trials will be allowed to finish even a small fraction
of the length needed train to convergence (<code class="docutils literal notranslate"><span class="pre">max_length</span></code>). This aggressive early stopping behavior
allows the searcher to start more trials for a wider exploration of hyperparameter configurations,
at the risk of discarding a configuration too soon.</p>
<p>On the other end, <code class="docutils literal notranslate"><span class="pre">conservative</span></code> mode is more similar to a <code class="docutils literal notranslate"><span class="pre">random</span></code> search, in that it performs
significantly less pruning. Extra ASHA subroutines are spawned with fewer rungs and longer training
lengths to account for the high percentage of trials eliminated after only a short time. However, a
<code class="docutils literal notranslate"><span class="pre">conservative</span></code> adaptive search will only explore a small fraction of the configurations explored
by an <code class="docutils literal notranslate"><span class="pre">aggressive</span></code> search, given the same budget.</p>
<p>Once the number and types of calls to ASHA are determined (via <code class="docutils literal notranslate"><span class="pre">mode</span></code>), the adaptive algorithm
will allocate training length budgets to the ASHA subroutines, from the overall budget for the
adaptive algorithm (user-specified through <code class="docutils literal notranslate"><span class="pre">budget</span></code>). This determines the number of trials at each
rung (N in the above ASHA example).</p>
</section>
</section>
<section id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="Permalink to this heading">#</a></h2>
<p><strong>Q: How do I control how long a trial is trained for before it is potentially discarded?</strong></p>
<p>The training length is guaranteed to be at least <code class="docutils literal notranslate"><span class="pre">max_length</span> <span class="pre">/</span> <span class="pre">256</span></code> by default, or <code class="docutils literal notranslate"><span class="pre">max_length</span> <span class="pre">/</span>
<span class="pre">divisor</span> <span class="pre">^</span> <span class="pre">max_rungs-1</span></code> in general. It is recommended to configure this in records or epochs if the
<code class="docutils literal notranslate"><span class="pre">global_batch_size</span></code> hyperparameter is not constant, to ensure each trial trains on the same amount
of data.</p>
<p><strong>Q: How do I make sure ``x`` trials are run the full training length (``max_length``)?</strong></p>
<p>The number of initial trials is determined by a combination of <code class="docutils literal notranslate"><span class="pre">mode</span></code>, <code class="docutils literal notranslate"><span class="pre">max_trials</span></code>,
<code class="docutils literal notranslate"><span class="pre">divisor</span></code>, <code class="docutils literal notranslate"><span class="pre">max_rungs</span></code>, <code class="docutils literal notranslate"><span class="pre">max_length</span></code> and <code class="docutils literal notranslate"><span class="pre">bracket_rungs</span></code>. Here is a rule of thumb for the
default configuration of <code class="docutils literal notranslate"><span class="pre">max_rungs:</span> <span class="pre">5</span></code> and <code class="docutils literal notranslate"><span class="pre">divisor:</span> <span class="pre">4</span></code>, with <code class="docutils literal notranslate"><span class="pre">mode:</span> <span class="pre">standard</span></code> and a large
enough <code class="docutils literal notranslate"><span class="pre">max_trials</span></code>:</p>
<ul class="simple">
<li><p>The initial number of trials is <code class="docutils literal notranslate"><span class="pre">max_trials</span></code>.</p></li>
<li><p>To ensure that <code class="docutils literal notranslate"><span class="pre">x</span></code> trials are run <code class="docutils literal notranslate"><span class="pre">max_length</span></code>, set <code class="docutils literal notranslate"><span class="pre">max_trials</span></code> high enough for the
brackets with their halving rate (the <code class="docutils literal notranslate"><span class="pre">divisor</span></code>) to allow <code class="docutils literal notranslate"><span class="pre">x</span></code> trials to make it to the final
<code class="docutils literal notranslate"><span class="pre">rungs</span></code>. This can be viewed by the command describe below.</p></li>
</ul>
<p>A configuration setting that meets set goals can be found by trial and error. The command</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>det<span class="w"> </span>preview-search<span class="w"> </span>&lt;file_name.yaml&gt;
</pre></div>
</div>
<p>will display information on the number of trials versus training length for the configuration
specified in <code class="docutils literal notranslate"><span class="pre">file_name.yaml</span></code>.</p>
<p><strong>Q: The adaptive algorithm sounds great so far. What are its weaknesses?</strong></p>
<p>In our experience, early-stopping works well across a variety of deep learning models. However,
there may be some search spaces in which early-stopping underperforms simple random search. This can
happen if model complexity varies drastically in a search space leading to different converge rates
or if the search space contains hyperparameters that are strongly correlated with training length.</p>
</section>
</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> {your-title}
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-start">Quick start</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#details">Details</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">ASHA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-asynchronous-halving">Why Asynchronous Halving?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-over-asha">Adaptive over ASHA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#faq">FAQ</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By lb
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, lb.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>